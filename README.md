# Multi-Party-TSS (ECDSA-DKLs23)

**To jump straight to running some nodes, please refer to the Docker instructions in the [section below](#run-an-example-of-the-full-system).**

For a guide on how to interact between a web frontend and a deployed DKLs23 network, please refer to [accompanying documentation](https://silence-laboratories.gitbook.io/silent-shard-network/aMIAGxSQSQ8mPaJGuh0i/) and [simple frontend demo page](https://gitlab.com/com.silencelaboratories/silent-shard/dkls23/dkls23-rs-public-demo). Please note that whilst the MPC security philosophy is configurable, by default it will expect an accompanying authorisation server to be running. A sensible default is provided, with its own documentation, in the `auth_server` directory.

**Silent Shard** has been built using a cryptographic base of **Multiparty computation (MPC).** MPC enables a set of parties that do not trust each other to try to jointly compute a function (digital signature generation in this case) over their inputs (key shards in this case) while keeping those inputs privately stored with them. Threshold signatures are a case enabled by multiparty computation where a threshold number of parties, out of the previously agreed group of approving (participating) nodes, can compute a cryptographic digital signature. ECDSA is one type of such a signature scheme based on elliptic curves.

Threshold Signatures (TSS) scheme protocols are multi-step and interactive protocols built through cryptographic primitives and zero-knowledge proofs to generate an indistinguishable signature as generated by a wallet holding the private key in one place.

TSS consists of three stages:

- Distributed Key Generation (DKG),
- Distributed Signature Generation, and
- Proactive Security with Key rotation/refresh.

These functions involve cryptographic computing at the participating nodes of the MPC quorum and exchanges of rounds of messages which ultimately lead to the generation of a valid signature at the requested node. These computing nodes can be any device with sufficient computational and memory capability, including but not limited to smartphones, server nodes, and edge devices.

The basic philosophy behind Silent Shard remains that no single device holding the private key can be used to generate signatures and move digital assets. The private key is shared among multiple computing nodes so that no party has any information about the key. Then, in order to generate a signature, the threshold number of devices run a secure two-party computation protocol that generates the signature without revealing anything about the parties' key shares to each other. These devices may or may not be associated with the same person or organization and can be any form factor. Thus, one could use this to create a wallet, sharing the private key between a mobile and a laptop, or between a mobile and a VM in the cloud, and so on.

# Articles and links

- DKLs23 https://eprint.iacr.org/2023/765.pdf
- DKG based on Protocol 6.1 https://eprint.iacr.org/2022/374.pdf
- 1 out of 2 Endemic OT Fig.8 https://eprint.iacr.org/2019/706.pdf
- All-but-one OTs from base OTs: Fig.13 and Fig.14 https://eprint.iacr.org/2022/192.pdf
- Generation of _sent_seed_list_ and _rec_seed_list_ values ​​based on Protocol 2.2 Pairwise Randomization [dkls23_preprint.pdf](docs/dkls23_preprint.pdf)
- SoftSpokenOT protocol https://eprint.iacr.org/2022/192.pdf
- Instantiation of SoftSpokenOT based on Fig.10 https://eprint.iacr.org/2015/546.pdf
- Proactive security definition, Section 2 https://www.iacr.org/archive/eurocrypt2006/40040601/40040601.pdf

# Protocol

Please note that the latest library of Silent Shard is based on DKLs23 TSS protocol.

# DKLs23 upgrades over DKLs19

- Threshold ECDSA in Three Rounds: Now matches the Schnorr protocol.
- Enabled by well-chosen correlation + simple new consistency check.
- Black box use of UC 2-round 2P-MUL. It is to be noted that OT-based protocols satisfy UC, but AHE is more complicated.
- No (explicit) ZK proofs during signing or DKG; light protocol and straightforward UC analysis.

<br/>

# Quick Start: SL-Demo website

## Run an example of the full system.

- To do so, first acquire a Personal Access Token from GitLab,
  [here](https://gitlab.com/-/profile/personal_access_tokens).
  Give it read access to repositories, and paste it into the file `./dkls23_token.txt`.

```bash
echo "your-PAT-here" > ./dkls23_token.txt
```

- Make sure you have `demo_page` submodule fetched by calling `git submodule update --init`. The `demo_page` contains WebUI that you will use to access the DKLs functionality.
- In `demo_page` setup `.env` file. Description how to do it you can find [here](./demo_page/README.md#step-1-set-environment-variables)
- Then, in order to enable OAuth2 login, you need to create a firebase app and supply the account key to the `auth_server` code.
  Instructions on how to do this are [here](./auth_server/README.md#firebase-configuration)

Once that is placed correctly, you may run the following:

```
./run_local.sh
```

The script executes several steps:

1. Builds Docker image
2. Runs 3 nodes using `docker compose up -d`
3. Starts Web sever from `demo_page` directory

If you want to have more control and do some steps manually, below we describe them in more details.

### Build docker image

- To build the docker image for a `dkls-party`, you will need a personal
  access token from GitLab (Use this link,
  [here](https://gitlab.com/-/profile/personal_access_tokens)).
  Give it read access to repositories, and store it in a text file
  somewhere on your system.

- Then, you can build the image with the following command:

```shell
docker build -t dkls-party \
    --secret id=token,src=/path/to/file/containing/gitlab-token \
    .
```

Make sure you replace the `/path/to/file/containing/gitlab-token` with the actual path to your token file.

This image contains both an instance of `dkls-party`, and `msg-relay-svc` to facilitate communications.

### Start "all cloud nodes" MPC network

The `docker-compose.yml` file is pre-configured for 3 nodes.

```shell
docker compose up -d
```

This will run a stack of containers giving you three DKLs23 nodes.

### Run the demo

You may now run the webserver from `demo_page` directory.

- Call `npm install` and then `npm run dev`

<br/>

Each instance of the DKLs23 cloud node represents a
participant in an MPC network. In the actual system, one node could be
replaced by a load balancer and set (most likely dynamic) of the
computational node.

Each node is paired with an authorization server (from the `auth_server` directory).
This handles validation of the user input, and identity. When an action is
authorized, a token is issued keying that particular sequence of events as
allowed to occur. This will be deposited in a Redis cache, and nodes will check
for the existence of this token before proceeding with DKG or DSG events.

Three instances of `msg-relay-svc`, one for each MPC network
participant. Each computational node is configured to connect to its
instance of `msg-relay-svc.` Each message relay instance is configured
to connect to two others as its peer relay.

The last service is an instance of `msg-relay-svc` to receive setup
messages. It is a peer for all other message relay services, but all
other services are not peer for this instance.

<br/>

---

# Implementation of DKLs23 and related code

The crates in this repository use crate `sl-mpc-mate` and `sl-oblivious`
from [`sl-crypto`](https://gitlab.com/com.silencelaboratories/sl-crypto),
and building with cargo will require the user to perform a `git pull` on
that repository. If you don't have access, please contact a team member for help.

This stack is dockerised! We recommend reading this whole document for proper understanding,
but if you just want to see how it runs you can skip to [this section](#run-an-example-of-the-full-system)

# Crates

The DKLs23 codebase has several components. All are necessary to ensure smooth operation, and the relationship between them is important to understand.

## `dkls23-rs`

This is the core crate, and handles the cryptographic heavy lifting. The main functions are:

```rust
// Distributed Key Generation
dkls23::keygen::dkg::run()

// Key Refresh
dkls23::keygen::key_refresh::run()

// Distributed Signature Generation
dkls23::sign::dsg::run()

// and methods for creating partial signatures and then combining them into a final signature:
dkls23::sign::dsg::pre_signature()
dkls23::sign::dsg::create_partial_signature()
dkls23::sign::dsg::combine_partial_signature()
```

Please refer to the cargo-generated documentation for information on their usage.

## `crates/msg-relay-svc`

The DKLs23 algorithm has a complex communication flow. At times, all parties need
to exchange messages with a central message broker; other times, they need to be
able to communicate in a peer-to-peer manner. The communication structure is not
rigorously defined and will change from run to run - sessions will require
differing amounts of p2p communications. In order to handle this, a generalized
message broker has been created that allows highly flexible messaging within a network.

This is a driver for a simple implementation of a message relay service. It handles
both peer-to-peer communications (defined when it is invoked) and broadcasts from
a central coordinator, and by temporarily caching messages in volatile memory,
can act as a message buffer for devices with unreliable connections (e.g. mobile phones).

Broadly speaking, it follows something analogous to a pub/sub model, but without
the "sub" aspect, and with some custom logic to allow for party identities, and
for specific messages to be requested from specific entities.
Rather than subscribing to a channel, parties request a specific message by
constructing a message ID from the hash of the sender, receiver (if any), a
message tag (e.g. `keygen message 4`, or something similar), and an instance ID.
If the corresponding message exists with the relay, it is returned.

A few examples how to run it:

```shell
# Default options
cargo run -p msg-relay-svc

# or, with some trace output
RUST_LOG=info cargo run -p msg-relay-svc

# and listen on more then one addr:port
cargo run -p msg-relay-svc -- \
  --listen 0.0.0.0:8080 \
  --peer ws://localhost:8081/v1/msg-replay
```

The option `--listen` understands both IPv4 and IPv6 addresses.

The option `--peer` defines a peer instance. If the instance receives an ASK
message and there is no corresponding ready message then it forwards the ASK
message to all peers.

## `crates/msg-relay`

A reusable reference implementation of a message relay.
`msg-relay-svc` is built using this one.

## `crates/msg-releay-client`

This is client library to access message relay service.

An implementation of `sl_mpc_mate::message::Relay` trait.

## `crates/dkls-party`

This command line utility to execute all steps of distributed
key generation (DKG) and distributed signature generation (DSG).
Invoking this handles the complete process, and returns the output.

The simplest way to build and run it would be:

```shell
cargo run -p dkls-party -q --release -- --help
```

The following scripts invoke the DKG and DSG components as a script -
for more information on how exactly this is done, we recommend
inspecting these scripts directly.

### `crates/dkls-party/scripts/dkg.sh`

This is a helper script to generate all the required keys for a party,
create an initial message (a setup message), execute the distributed
key generation and save the resulting keyshares to files.

```shell
# create a directory for keyshares and various addtional files
mkdir ./data

# we assume that msg-relay-svc is running on this machine and
# it listens on 127.0.0.1:8080 (this is default)

# the following command will execute distributed key generation
#
# N=5 - number of participants
# T=3 - theshold
#
# show trace output as much as possible and place all data files
# into directory `./data`
#
RUST_LOG=debug DEST=./data ./crates/dkls-party/scripts/dkg.sh 5 3

# a last line of output pf dsg.sh will be public key of new key

# make sure there are keyshares. Should be one for each party

ls -l ./data/keyshare.*

```

### `crates/dkls-party/dsg.sh`

We generated key, now we are ready to generate a signature with it.

```shell
# we will use ./data directory populated by dkg.sh script

# This command will generate a signature for message "test"
# using first 3 keyshares, parties 0, 1, and 2.
#
RUST_LOG=debug DEST=./data ./crates/dkls-party/scripts/dsg.sh "test" 0 1 2
```

Please, read the comments in these scripts to get more details.

### Generate distributed key

To trigger the DKG session, a script is provided.

```shell
./crates/dkls-party/scripts/dkg-setup.sh 3 2
```

This will generate distributed key and print the resulting public key.

This command will generate a setup message for key generation and
publish it to the designated message relay instance.

Then, it will contact all computation nodes and send them the instance ID.
This is signal to start distributed key generation, and from there the nodes
will communicate directly with one another to carry out the protocol.

### Generate signature

```shell
./crates/dkls-party/scripts/dsg-setup.sh \
   <public key> \
   "message to sign" \
   0 1
```

The command above will trigger the nodes to generate a signature,
and print it to the console.

## Configuration

The library uses two thread pools. One is controlled by variable
`RAYON_NUM_THREADS` and another one by `TOKIO_WORKER_THREADS`. Sum of
these numbers should match a number of CPU cores available for an
instance of a service.

# BIP32: Non-Hardened Derivation

To sign a message using the key derived from the master key_share using the chain path such as m/0/1/42 you can do as follows:

Сreate chain_path variable

```rust
let chain_path: DerivationPath = "m/0/1/42".parse().unwrap();
```

and use it to create a `ValidatedSetup` structure and create a signature.
For more information see the example `./examples/dsg.rs`

```
cargo run --example dsg --release
```

---

### Wasm bindings.

SL-Demo uses Wasm bindings for sessions that involve the browser performing some compute. To building them locally use the following
commands:

```shell
rustup target add wasm32-unknown-unknown
cargo install wasm-opt
cargo install wasm-pack
wasm-pack build -t web wrapper/wasm
```

The last command runs the build and put NPM package at wrapper/wasm/pkg.

### Start the frontend

To interact with the demo from a browser, you can run the frontend with node.

First, build the WASM package, as above.

Some development variables need to be set correctly.
Edit `demo_page/vite.config.ts`:

```js
//import { proxy } from "./proxy";
import { proxy } from "./proxy-local";
```

Ensure that the local proxy is the one being used! Comment first line and uncomment second one - we want to use the local proxy.

Assuming that MPC network is started by docker-compose,
now we could run local dev server.

```shell
env DKLS_LOCAL=yes yarn dev
```

Then, simply run a dev server.

```
cd wrapper/wasm/demo
npm install
npm run dev
```

Open http://localhost:5173/ and follow instructions.

### Deploying to `fly.io`

As an example deployment, we have created a configuration to host a set of nodes (spread across several machines) to the `fly.io` platform. Please refer to the document [here](./fly_instructions.md) for details on this.

From Dung
